ConvNetFlex_ep200
training time:
20230224_131703
ConvNetFlex_ep200
training time:
20230224_131931
ConvNetFlex_ep200
training time:
20230224_132758
Finished TrainingConvNetFlex_ep300
training time:
20230224_133146
ConvNetFlex_ep300
training time:
20230224_133238
Finished TrainingRNN_test_ep300
training time:
20230224_134255
RNN_test_ep300
training time:
20230224_134422
RNN_ep300
training time:
20230224_134504
RNN_LSTM_ep300
training time:
20230224_135034
RNN_LSTM_ep300
training time:
20230224_135139
RNN_LSTM_ep100
training time:
20230224_135338
Epoch [1/100], Step [225/225], Loss: 1.0893
Epoch [11/100], Step [225/225], Loss: 1.1145
Epoch [21/100], Step [225/225], Loss: 1.0906
Epoch [31/100], Step [225/225], Loss: 1.1195
Epoch [41/100], Step [225/225], Loss: 1.0970
Epoch [51/100], Step [225/225], Loss: 1.0825
Epoch [61/100], Step [225/225], Loss: 1.0813
Epoch [71/100], Step [225/225], Loss: 1.0929
training time:
20230226_221305
training time:
20230226_221653
training time:
20230226_221808
Epoch [1/100], Step [225/225], Loss: 1.6978
Epoch [11/100], Step [225/225], Loss: 1.0995
training time:
20230226_222647
Epoch [1/100], Step [225/225], Loss: 1.4988
Epoch [11/100], Step [225/225], Loss: 1.0845
Epoch [21/100], Step [225/225], Loss: 1.3713
training time:
20230226_223756
Epoch [1/100], Step [225/225], Loss: 1.1390
training time:
20230226_223955
training time:
20230226_224052
Epoch [1/100], Step [897/897], Loss: 1.2745
Epoch [11/100], Step [897/897], Loss: 0.3662
training time:
20230226_224815
Epoch [1/100], Step [897/897], Loss: 0.4244
training time:
20230226_224904
Epoch [1/100], Step [897/897], Loss: 0.8275
Epoch [11/100], Step [897/897], Loss: 1.8424
training time:
20230226_231119
training time:
20230226_231130
training time:
20230226_231504
training time:
20230226_231709
training time:
20230226_231948
training time:
20230226_232053
training time:
20230226_232407
training time:
20230226_232738
training time:
20230226_233245
training time:
20230226_233302
training time:
20230226_234249
training time:
20230226_234351
Epoch [1/100], Step [897/897], Loss: 1.2486
training time:
20230226_234436
Epoch [1/100], Step [897/897], Loss: 0.9261
Epoch [11/100], Step [897/897], Loss: 0.3185
Epoch [21/100], Step [897/897], Loss: 2.2843
training time:
20230227_000146
Epoch [1/15], Step [897/897], Loss: 0.4797
Epoch [2/15], Step [897/897], Loss: 0.5165
Epoch [3/15], Step [897/897], Loss: 0.5177
training time:
20230227_000440
Epoch [1/15], Step [897/897], Loss: 0.5712
Epoch [2/15], Step [897/897], Loss: 0.5371
Epoch [3/15], Step [897/897], Loss: 1.3662
training time:
20230227_000713
Epoch [1/15], Step [897/897], Loss: 0.7284
Epoch [2/15], Step [897/897], Loss: 0.8255
Epoch [3/15], Step [897/897], Loss: 1.4693
Epoch [4/15], Step [897/897], Loss: 0.5265
Epoch [5/15], Step [897/897], Loss: 2.6782
Epoch [6/15], Step [897/897], Loss: 0.6815
Epoch [7/15], Step [897/897], Loss: 0.6283
Epoch [8/15], Step [897/897], Loss: 0.6816
Epoch [9/15], Step [897/897], Loss: 1.4160
Epoch [10/15], Step [897/897], Loss: 1.0261
Epoch [11/15], Step [897/897], Loss: 0.4610
Epoch [12/15], Step [897/897], Loss: 0.5319
Epoch [13/15], Step [897/897], Loss: 0.9933
Epoch [14/15], Step [897/897], Loss: 0.6811
Epoch [15/15], Step [897/897], Loss: 0.4691
Finished Training